# todogen_llm.py
from openai import OpenAI
# from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed
from filter_useful_data_to_dict import get_formatted_data
from filter_message_list import get_message_ids
from config_loader import get_mysql_config, get_openai_config
from pathlib import Path
import argparse
import json
import sys
import os
import re
import io


# ä¿®æ­£åçš„æ ‡å‡†æµç¼–ç è®¾ç½®
sys.stdin = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', write_through=True)
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', write_through=True)

client = OpenAI(
    api_key=get_openai_config()['api_key'],
    base_url=get_openai_config()['base_url']
)

# async def load_formatted_data():
def load_formatted_data():
    """åŒæ­¥è·å–æ ¼å¼åŒ–æ•°æ®"""
    db_config = {
        "host": get_mysql_config()['host'],
        "database": get_mysql_config()['database'],
        "password": get_mysql_config()['password']
    }

    target_ids = get_message_ids()
    # return await get_formatted_data(db_config, target_ids)
    return get_formatted_data(db_config, target_ids)

def process_data(input_data: dict) -> dict:
    """å¤„ç†å­—å…¸æ•°æ®å¹¶ç›´æ¥è¿”å›ç»“æœ"""
    if not all(isinstance(k, str) and isinstance(v, str) for k, v in input_data.items()):
        raise ValueError("è¾“å…¥æ•°æ®ä¸ºç©º")
    
    results = {}
    errors = {}

    # å°†æ•°æ®åˆ†æ‰¹æ¬¡å¤„ç†ï¼ˆæ¯10æ¡ä¸ºä¸€æ‰¹ï¼‰
    items = list(input_data.items())
    batch_size = 8
    threads_per_batch = 3

    for batch_idx in range(0, len(items), batch_size):
        batch = items[batch_idx:batch_idx + batch_size]
        print(f"ğŸš€ æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {batch_idx//batch_size + 1}/{len(items)//batch_size + 1}")
        
        with ThreadPoolExecutor(max_workers=threads_per_batch) as executor:
            futures = {
                executor.submit(process_single_message, msg_id, content): msg_id
                for msg_id, content in batch
            }
            
            for future in as_completed(futures):
                msg_id = futures[future]
                try:
                    result = future.result()
                    clean_result = json_parser(result)
                    results.update(clean_result)
                except Exception as e:
                    error_msg = f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}"
                    print(f"æ¶ˆæ¯ID {msg_id}: {error_msg}")
                    errors[msg_id] = error_msg

    if errors:
        with open("processing_errors.json", "w", encoding="utf-8") as f:
            json.dump(errors, f, ensure_ascii=False, indent=2)
        print(f"é”™è¯¯ä¿¡æ¯å·²ä¿å­˜åˆ° processing_errors.jsonï¼Œå…± {len(errors)} æ¡")

    return results

def process_single_message(msg_id: str, content: str) -> str:
    """å•æ¡æ¶ˆæ¯å¤„ç†åŒ…è£…å‡½æ•°"""
    try:
        return extract_single_message(msg_id, content)
    except Exception as e:
        raise RuntimeError(f"APIè°ƒç”¨å¤±è´¥: {str(e)}") from e

def json_parser(raw_text):
    try:
        return json.loads(raw_text)
    except json.JSONDecodeError:
        # å°è¯•ä»æ–‡æœ¬ä¸­æå–JSONéƒ¨åˆ†
        json_str = re.search(r'{.*}', raw_text, re.DOTALL)
        if json_str:
            try:
                return json.loads(json_str.group())
            except json.JSONDecodeError:
                # æ¸…ç†å¼•å·é—®é¢˜
                cleaned_text = json_str.group().replace("'", '"')
                return json.loads(cleaned_text)
            
        else:
            return {"error": "æ— æ³•ä»æ–‡æœ¬ä¸­æå–JSON", "raw_text": raw_text}

def extract_single_message(message_id, content):
    """å¤„ç†å•æ¡æ¶ˆæ¯å¹¶æå–å…³é”®ä¿¡æ¯"""
    # è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦ï¼Œé˜²æ­¢å†…å®¹ç ´åJSONæ ¼å¼
    content_escaped = content.replace('"', '\\"').replace('\n', '\\n')
    
    combined_prompt = f"""
# ä»»åŠ¡è¯´æ˜
ä½ æ˜¯ä¸€ä¸ªé«˜çº§ä¿¡æ¯æå–AIï¼Œéœ€è¦ä»å„ç±»æ¶ˆæ¯ä¸­æ™ºèƒ½è¯†åˆ«å¹¶ç»“æ„åŒ–ä»¥ä¸‹å…³é”®ä¿¡æ¯ï¼š
1. æˆªæ­¢æ—¶é—´ï¼ˆend_timeï¼‰
2. åœ°ç‚¹ä¿¡æ¯ï¼ˆlocationï¼‰
3. å¾…åŠå†…å®¹ï¼ˆtodo_contentï¼‰
4. ç´§æ€¥ç¨‹åº¦ï¼ˆurgencyï¼‰

# æ ¸å¿ƒèƒ½åŠ›è¦æ±‚
## 1. æ—¶ç©ºç†è§£èƒ½åŠ›
- èƒ½è¯†åˆ«ç»å¯¹æ—¶é—´ï¼ˆå¦‚"2025-03-31 12:00"ï¼‰
- èƒ½è®¡ç®—ç›¸å¯¹æ—¶é—´ï¼ˆå¦‚"12å°æ—¶å†…"éœ€ç»“åˆå¼€å§‹æ—¶é—´è®¡ç®—ï¼‰
- èƒ½åŒºåˆ†çº¿ä¸Š/çº¿ä¸‹åœºæ™¯

## 2. è¯­ä¹‰æ¨ç†èƒ½åŠ›
- å¯¹æ¨¡ç³Šè¡¨è¿°è¿›è¡Œåˆç†æ¨æ–­ï¼ˆå¦‚"å°½å¿«å–ä»¶"å¯è§†ä¸ºurgentï¼‰
- è¯†åˆ«åŒä¹‰è¡¨è¿°ï¼ˆå¦‚"ä¸°å·¢æŸœ/å¿«é€’æŸœ/æ™ºèƒ½æŸœ"ç»Ÿä¸€ä¸ºä¸°å·¢å¿«é€’æŸœï¼‰
- å¤„ç†ä¸å®Œæ•´ä¿¡æ¯ï¼ˆå¦‚ç¼ºå°‘å…·ä½“æ—¶é—´æ—¶æ ‡è®°ä¸ºnullï¼‰

## 3. åœºæ™¯é€‚åº”èƒ½åŠ›
èƒ½å¤„ç†ä»¥ä¸‹å…¸å‹åœºæ™¯ï¼š
âœ… ç‰©æµå¿«é€’ï¼ˆå–ä»¶ç /é©¿ç«™é€šçŸ¥ï¼‰
âœ… å¤–å–é…é€ï¼ˆæ™ºèƒ½æŸœå­˜æ”¾ï¼‰
âœ… ä¼šè®®é‚€çº¦ï¼ˆçº¿ä¸Š/çº¿ä¸‹ä¼šè®®ï¼‰
âœ… å¾…åŠæé†’ï¼ˆå«æ—¶é—´è¦æ±‚çš„ä»»åŠ¡ï¼‰
âœ… å…¶ä»–ä¸´æ—¶æ€§äº‹åŠ¡

# è¾“å…¥æ•°æ®
{{
    "message_id": "{message_id}",
    "content": "{content_escaped}"
}}

# å¤„ç†è§„åˆ™
## æ—¶é—´å¤„ç†
1. ä¼˜å…ˆæå–æ˜¾å¼æ—¶é—´ï¼ˆå¦‚"23:00å‰"ï¼‰
2. æ¬¡é€‰ç›¸å¯¹æ—¶é—´ï¼ˆå¦‚"å­˜æŸœè¶…è¿‡12å°æ—¶"éœ€è®¡ç®—ï¼‰
3. æ— æ—¶é—´çº¿ç´¢åˆ™å¡«null
4. å¦‚æœå¼€å§‹æ—¶é—´start_time(å¼€å§‹æ—¶é—´ä¸º2025-03-31T15:01:37)æˆ–è€… duration/æ—¶é•¿ ï¼ˆå¦‚ä¼šè®®æ—¶é•¿ï¼‰éƒ½æœ‰ï¼Œé‚£end time = start time  + countdown æˆ–è€… end time = start time  + durationâ€

## åœ°ç‚¹å¤„ç†
1. çº¿ä¸Šåœºæ™¯æ ‡è®°å¹³å°/å·¥å…·ï¼ˆå¦‚"é£ä¹¦ä¼šè®®"ï¼‰
2. çº¿ä¸‹åœºæ™¯æå–å®Œæ•´åœ°å€
3. æ¨¡ç³Šåœ°å€éœ€è¡¥å……ç‰¹å¾ï¼ˆå¦‚"å…¬å¸å‰å°"ï¼‰

## å†…å®¹æç‚¼
1. é‡‡ç”¨"åŠ¨è¯+æ ¸å¿ƒåè¯"ç»“æ„
2. ä¿ç•™ä¸šåŠ¡å…³é”®è¯ï¼ˆå¦‚"PR Mergeè®¨è®º"ï¼‰
3. å»é™¤ä¿®é¥°æ€§è¯è¯­

## ç´§æ€¥ç¨‹åº¦
- urgentï¼šéœ€ç«‹å³å¤„ç†ï¼ˆå¦‚"å³å°†è¶…æ—¶"ï¼‰
- importantï¼šæœ‰æ—¶é™è¦æ±‚
- unimportantï¼šæ— æ—¶é—´å‹åŠ›

# è¾“å‡ºç¤ºä¾‹
```json
{{
    "{message_id}": {{
        "end_time": "ISO8601æ ¼å¼æˆ–null",
        "location": "ç±»å‹(çº¿ä¸Š/çº¿ä¸‹):å…·ä½“æè¿°",
        "todo_content": "æœ€ç®€ä»»åŠ¡æè¿°",
        "urgency": "urgent/important/unimportant"
    }}
}}
"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": combined_prompt}],
        temperature=0.0
    )
    return response.choices[0].message.content

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='å…³é”®ä¿¡æ¯æå–å·¥å…·')
    default_output = str(Path(r"D:\python_study\ILoveDo\todogen_LLM\result.json"))
    parser.add_argument('-o', '--output', default=default_output, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    try:
        args = parser.parse_args()
        # formatted_data = asyncio.run(load_formatted_data()) # ç›´æ¥åŒæ­¥è°ƒç”¨
        formatted_data = load_formatted_data() # ç›´æ¥åŒæ­¥è°ƒç”¨
        results = process_data(formatted_data)
        
        os.makedirs(os.path.dirname(args.output), exist_ok=True)
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print("âœ… å¤„ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³:", args.output)
        
    except Exception as e:
        print(f"è¿è¡Œé”™è¯¯: {str(e)}")
        sys.exit(1)


"""
1ã€å¯¹ç¡¬ç¼–ç å¯†é’¥ã€‚æ•°æ®åº“é…ç½®ä¿¡æ¯è¿›è¡Œéšè—å¤„ç†
2ã€2. LLM æç¤ºæ¨¡æ¿å…³é”®é—®é¢˜
æœ€å…³é”®çš„é—®é¢˜æ˜¯ extract_single_message() å‡½æ•°ä¸­çš„æç¤ºæ¨¡æ¿æ²¡æœ‰æ­£ç¡®å¼•ç”¨ä¼ å…¥çš„ message_id å’Œ content å‚æ•°

"""